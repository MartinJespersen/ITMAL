{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ITMAL Exercise\n",
    "\n",
    "REVISIONS| |\n",
    "---------| |\n",
    "2018-1218| CEF, initial.\n",
    "2018-0214| CEF, major update.\n",
    "2018-0220| CEF, added code reference.\n",
    "2018-0220| CEF, fixed revision table malformatting.\n",
    "2018-0225| CEF, minor text updates, and made Qc optional.\n",
    "2019-1008| CEF, updated to ITMAL E19.\n",
    "\n",
    "## Model capacity and under/overfitting\n",
    "\n",
    "NOTE: text and code to the exercise it taken from \n",
    "\n",
    "* https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\n",
    " \n",
    "\n",
    "This example demonstrates the problems of underfitting and overfitting and\n",
    "how we can use linear regression with polynomial features to approximate\n",
    "nonlinear functions. \n",
    "\n",
    "The plot below shows the function that we want to approximate,\n",
    "which is a part of the cosine function. In addition, the samples from the\n",
    "real function and the approximations of different models are displayed. The\n",
    "models have polynomial features of different degrees. We can see that a\n",
    "linear function (polynomial with degree 1) is not sufficient to fit the\n",
    "training samples. \n",
    "\n",
    "This is called **underfitting**. A polynomial of degree 4\n",
    "approximates the true function almost perfectly. However, for higher degrees\n",
    "the model will **overfit** the training data, i.e. it learns the noise of the\n",
    "training data.\n",
    "\n",
    "We evaluate quantitatively **overfitting**/**underfitting** by using\n",
    "cross-validation. We calculate the mean squared error (MSE) on the validation\n",
    "set, the higher, the less likely the model generalizes correctly from the\n",
    "training data.\n",
    "\n",
    "### Qa Explain the polynomial fitting via code review\n",
    "\n",
    "Review the code below, write a __short__ code review summary, and explain how the polynomial fitting is implemented?\n",
    "\n",
    "Do not dig into the plotting details, but explain the outcome of the plots.\n",
    "\n",
    "Answer:\n",
    "Der er bliver først generet data fra en cosinus funktion, som der tilføjes gaussisk støj til.\n",
    "Det køres et loop for tre forskellige grader, som skal bruges i en til at transformere en feature om til antal_nye_feature = (n_feature+degrees)!/(n_feature!degrees!).\n",
    "Herefter bliver lineær regression brugt til at finde vægtene. Både transformering og regression bliver tilføjet en pipeline, som der laves et fit af.\n",
    "Der laves ogs[ k-fold CV på dataet for at se hvor godt modellerne fitter med de forskellige grader, hvor der tages en middelværdi af de ti resultatter for hver grad.\n",
    "Der laves et plot for hver regression med de forskellige grader med resultaterne op imod de predikterede værdier.\n",
    "Det ses at ved brug af en grad underfitter dataet, den ene grad ikke er nok til at beskrive dataet. \n",
    "Der ses at ved 4 grader passer de prediktered værdier meget godt hvor middelværdien også er meget lav for MSE.\n",
    "Det sidste plot overfitter meget, da der er alt for mange grader, og alt støjen tages også med i regression, hvilke giver en meget høj middelværdi af MSE cost, hvilket tydelit ses i plottet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Iterating...degrees= [1, 4, 15]\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "'mean_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m                 \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSCORERS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_squared_error'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8b4af4c5b433>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# Evaluate the models using crossvalidation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean_squared_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mscore_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    381\u001b[0m     \"\"\"\n\u001b[0;32m    382\u001b[0m     \u001b[1;31m# To ensure multimetric format is not supported\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[1;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[0;32m    401\u001b[0m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 403\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    404\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[1;31m# Heuristic to ensure user has not passed a metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36mget_scorer\u001b[1;34m(scoring)\u001b[0m\n\u001b[0;32m    361\u001b[0m             raise ValueError('%r is not a valid scoring value. '\n\u001b[0;32m    362\u001b[0m                              \u001b[1;34m'Use sorted(sklearn.metrics.SCORERS.keys()) '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m                              'to get valid options.' % scoring)\n\u001b[0m\u001b[0;32m    364\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m         \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'mean_squared_error' is not a valid scoring value. Use sorted(sklearn.metrics.SCORERS.keys()) to get valid options."
     ]
    }
   ],
   "source": [
    "# TODO: Qa...review this code\n",
    "\n",
    "# NOTE: code from https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def true_fun(X):\n",
    "    return np.cos(1.5 * np.pi * X)\n",
    "\n",
    "def GenerateData(n_samples = 30):\n",
    "    X = np.sort(np.random.rand(n_samples))\n",
    "    y = true_fun(X) + np.random.randn(n_samples) * 0.1\n",
    "    return X, y\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X, y = GenerateData()\n",
    "degrees = [1, 4, 15]\n",
    "    \n",
    "print(\"Iterating...degrees=\",degrees)\n",
    "plt.figure(figsize=(14, 5))\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(1, len(degrees), i + 1)\n",
    "    plt.setp(ax, xticks=(), yticks=())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree=degrees[i], include_bias=False)\n",
    "    \n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([\n",
    "            (\"polynomial_features\", polynomial_features),\n",
    "            (\"linear_regression\", linear_regression)\n",
    "        ])\n",
    "    pipeline.fit(X[:, np.newaxis], y)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X[:, np.newaxis], y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    \n",
    "    score_mean = -scores.mean()\n",
    "    print(f\"  degree={degrees[i]:4d}, score_mean={score_mean:4.2f},  {polynomial_features}\")   \n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    y_pred = pipeline.predict(X_test[:, np.newaxis])\n",
    "    \n",
    "    # Plotting details\n",
    "    plt.plot(X_test, y_pred          , label=\"Model\")\n",
    "    plt.plot(X_test, true_fun(X_test), label=\"True function\")\n",
    "    plt.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.2e}(+/- {:.2e})\".format(degrees[i], -scores.mean(), scores.std()))\n",
    "\n",
    "plt.show()\n",
    "print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Explain the capacity and under/overfitting concept\n",
    "\n",
    "Write a textual description of the capacity and under/overfitting concept using the plots in the code above.\n",
    "\n",
    "What happens when the polynomial degree is low/medium/high with respect to under/overfitting  concepts? Explain in details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qb...in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [OPTIONAL] Qc Score method\n",
    "\n",
    "Why is the scoring method called `neg_mean_squared_error` in the code? What happens if you try to set it to `mean_squared_error`?\n",
    "\n",
    "```python\n",
    "scores = cross_val_score(pipeline, X[:, np.newaxis], y, scoring=\"mean_squared_error\", cv=10)\n",
    "```\n",
    "\n",
    "Why does the Degree 15 model have a MSE of 1.81E8, and hence not the best MSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Qc..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python37664bittensorflowcondacaa0349ce768477fbcd6b16d858d0fb7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}